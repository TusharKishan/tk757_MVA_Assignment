---
title: "Untitled"
author: "Tushar"
date: "2024-04-29"
output: html_document
---

```{r}
library(readr)
library(stats)
library(cluster)
library(factoextra)
library(magrittr)
library(NbClust)
library(FactoMineR)
library(psych)

#PCA Analysis
social_media <- read_csv("/Users/tusharkishan/Desktop/Multivariate/Social\ Media/Project/Social\ Media.csv")
attach(social_media)
str(social_media)

data_scaling <- scale(social_media[-1])
cor(data_scaling)

#Ans)The correlation matrix you provided shows the pairwise correlations between different social media platforms (Instagram, LinkedIn, Snapchat, Twitter, WhatsApp/WeChat, YouTube, OTT, and Reddit), as well as how you felt the entire week.These correlations can provide insights into how different social media platforms are related to each other. For example, if you see a high positive correlation between two platforms, it might suggest that users who are active on one platform are also likely to be active on the other. Conversely, a negative correlation might suggest that users tend to favor one platform over the other. Overall, the correlation matrix helps us understand the relationships between different social media platforms and how they might be related to how you felt during the week.

social_media_pca <- prcomp(social_media[,-1],scale=TRUE)
social_media_pca
summary(social_media_pca)

#Ans) The PCA Analysis shows us that the standard deviation of each principal component. The higher the standard deviation, the more important the component is in explaining the variability in the data. The first three PCs explain 60.45% of the variance, which is quite substantial.As we add more components, the cumulative proportion increases, eventually reaching 100% when all components are included.

fviz_eig(social_media_pca, addlabels = TRUE)

#Ans) The graph shows that the sum of first 4 PCs is 72%. Hence first 4 PCs should be considered

biplot(social_media_pca, cex = 0.6, col = c("blue", "red"))
#Ans) The biplot shows the projections of observations and variables onto the principal components. This helps us to visualize, how each observation and variable contributes to the principal components.Correlation between the variables is reflected by the angle between them. The smaller the angle, the more significant the correlation is.

fviz_pca_var(social_media_pca, col.var = "contrib",
             gradient.cols = c("#FF0000", "#00FF00", "#0000FF"),
             repel = TRUE)

#Ans) The above graph gives us a more clear visualization. From this graph it is clear that both Snapchat and Whatsapp/WeChat are more correlated.

res.pca <- PCA(social_media[-1], graph = FALSE)

fviz_pca_biplot(res.pca, repel = TRUE, col.var = "#FC4E07", geom = "text",
                 col.ind = "blue",
                 palette = c("#00AFBB", "#E7B800", "#FC4E07"),
                 legend.title = "Variables")


#Ans) From the graph it is clear that I am near the axis. Based on the diagram we can tell that my social media usage is relatively balanced or average compared to the other observations. Being near the zero line means that your scores on the principal component (PC) represented by the first axis are close to the overall average for the dataset.

#Cluster Analysis
matstd_social_media <- scale(social_media[-1])

fviz_nbclust(matstd_social_media, kmeans, method = "silhouette")
#Ans) As observed from the graph , the optimal number of clusters to choose would be 2

#K-Means clustering
set.seed(123)
km <- kmeans(matstd_social_media, centers = 4)
fviz_cluster(km, data = matstd_social_media)

#Ans) The graph shows us how students are divided into which cluster. As observed from the graph cluster 1 is an outlier and a seperate cluster. The cluster which I belong to is cluster 3. Cluster 3 has a relatively low social media usage compared to cluster 2 and cluster 4. The people belonging in cluster 2 and cluster 4 have a high social media usage.

#Factor Analysis
fit.pc <- principal(social_media[-1], nfactors=4, rotate="varimax")
fit.pc
fa.diagram(fit.pc)

#Ans) The factor analysis I've conducted explains that each factor explains a certain amount of variance in the data, with RC1 explaining the most variance (30%), followed by RC2 (27%), RC3 (24%), and RC4 (19%).The RMSR (root mean square of residuals) is a measure of how well the model fits the data, with lower values indicating a better fit. In your analysis, the RMSR is 0.1, which is a relatively good fit. Also the graoh shows what apps are students are using together. Also from the graph we can see that Whatsapp/Wechat, Instagram and Youtube are combined together because students might be using it more for to communicate , learn or entertain themselves. OTT, twiiter and Reddit is combined into one, as they are providing entertainment or insights which the student wants. Linkedin and how you felt the entire week is combined into one and snapchat is kept seperately

#Takeaway
#Ans) The combined findings of PCA, Cluster Analysis, and Factor Analysis demonstrate the diversity of class members' use of social media. There are substantial variances in how people utilize different platforms, which may be classified into diverse behavioral patterns associated with various causes. This study also helps identify certain groups in the class for targeted research or treatments based on their social media behavior, which improves our understanding of common social media usage trends.

```
```{r}
library(factoextra)
library(FactoMineR)
library(psych)
library(readr)
library(GGally)

social_media <- read_csv("/Users/tusharkishan/Desktop/Multivariate/Social\ Media/Social\ Media\ Multiple\ Regression/social_media_cleaned_new.csv")

str(social_media)

#Ans)A summary of responses from 21 individuals regarding their social media usage and various aspects of their week, such as mood, productivity, and sleep patterns. 
#Social Media Usage: The data includes columns for different social media platforms (e.g., Instagram, LinkedIn, Snapchat, Twitter, etc.) and the average time spent on each platform by the 21 individuals.
#Other Activities: The data also includes information about other activities, such as job interview calls received, networking done through coffee chats, and learning activities in terms of items created.
#Mood and Productivity: There is a column indicating whether individuals felt productive during the week, which could be correlated with their social media usage and other activities.
#Sleep Patterns: The data includes columns related to sleep, such as tiredness upon waking up and trouble falling asleep, both of which could be influenced by social media usage and daily activities.


social_media$`Trouble falling asleep_numeric` <- ifelse(social_media$`Trouble falling asleep` == "Yes", 1, 0)
str(social_media)

#Ans) A new column Trouble falling asleep_numeric is created where the values are 'num' data type

fit <- lm(`Trouble falling asleep_numeric` ~ Instagram + LinkedIn + SnapChat + Twitter + `Whatsapp/Wechat` + youtube + OTT + Reddit, data = social_media)
summary(fit)

#Ans) The output provides several important pieces of information about the model's performance:
#Residuals: These are the differences between the observed values of the dependent variable and the values predicted by the model. The summary provides statistics about the distribution of these residuals.
#Coefficients: These are the estimated coefficients for each independent variable in the model. Each coefficient represents the change in the dependent variable associated with a one-unit change in the corresponding independent variable, holding all other variables constant. The "Estimate" column shows the estimated coefficient value, the "Std. Error" column shows the standard error of the estimate, the "t value" column shows the t-statistic for testing the significance of the coefficient, and the "Pr(>|t|)" column shows the p-value associated with the t-statistic.
#Residual Standard Error: This is an estimate of the standard deviation of the residuals. It indicates the average amount that the observed values deviate from the predicted values.
#Multiple R-squared: This is a measure of how well the independent variables explain the variability in the dependent variable. It ranges from 0 to 1, with higher values indicating a better fit.
#Adjusted R-squared: This is a version of the R-squared value that has been adjusted for the number of independent variables in the model. It penalizes the R-squared value for including unnecessary variables.
#F-statistic: This is a test statistic for the overall significance of the model. It compares the variability explained by the model to the variability not explained by the model.
#p-value: This is the p-value associated with the F-statistic. It indicates the probability of obtaining an F-statistic as extreme as the one calculated, assuming that the null hypothesis (that all coefficients are zero) is true. A low p-value indicates that the model is statistically significant.

fit2 <- lm(`Trouble falling asleep_numeric` ~ Instagram + LinkedIn + SnapChat + `Whatsapp/Wechat` + youtube + OTT + Reddit, data = social_media)
summary(fit2)
#Ans) The given output from summary(fit) and summary(fit2), it appears that the p-value for the added variable (Twitter) in fit is already above 0.05 (0.799), indicating that Twitter is not a statistically significant predictor in the model fit. Hence we can continue with the 1st model itself

coefficients(fit)
#Ans) These coefficients represent the estimated effect of each predictor variable on the response variable, holding all other variables constant.

ggpairs(data = social_media, title = "Social Media Usage", cardinality_threshold = 30)
#Ans) The graph shows us that there is no linear relationship between the columns

confint(fit,level=0.95)

#Ans) The confint function provides the 95% confidence intervals for the coefficients.These intervals give a range of values within which we can be 95% confident that the true population parameter lies for each coefficient.

fitted(fit)
#Ans) The fitted function provides the fitted values for the multiple regression model fit.Each value in the output corresponds to a fitted value for each observation from my dataset.

residuals(fit)
#Ans) The residuals function gives you the residuals (the differences between the observed values and the fitted values) for the multiple regression model fit. These residuals indicate how well the model fits the data for each observation.

anova(fit)
#Ans) The ANOVA table shows the analysis of variance for the regression model fit.The table includes the following columns:
#Df: Degrees of freedom for each source of variation.
#Sum Sq: Sum of squares, which measures the total variation explained by each variable or the residuals.
#Mean Sq: Mean sum of squares, which is the sum of squares divided by its degrees of freedom.
#F value: The F-statistic, which is a ratio of the mean square for the variable to the mean square of the residuals. It indicates whether there is a significant difference in means between groups (or in this case, whether the variable is a significant predictor of Brand_numeric).
#Pr(>F): The p-value associated with the F-statistic, which indicates the probability of observing the data if the null hypothesis (that the variable has no effect) is true. Small p-values indicate that the variable is a significant predictor.

vcov(fit)
#Ans) The variance-covariance matrix for the coefficients in my model fit shows the estimated covariance between each pair of coefficients. This matrix is useful for understanding the uncertainty in your coefficient estimates and for calculating confidence intervals.Each element in the matrix represents the covariance between two coefficients.The diagonal elements of the matrix (from top left to bottom right) represent the variance of each coefficient estimate. The square root of these values gives the standard error of each coefficient estimate. The off-diagonal elements represent the covariance between different coefficient estimates. Positive values indicate that the coefficients tend to vary together, while negative values indicate that they tend to vary in opposite directions.

plot(fit)
#Ans) The plots play a key role in highlighting important issues and verifying the model's assumptions. They aid in visualizing the degree to which the model matches the data. A good model fit is indicated by random scatter in the residuals vs fitted plot, a straight line in the Q-Q plot, random scatter in the Scale-Location plot, and no influential outliers in the Residuals vs Leverage plot.

r_squared <- summary(fit)$r.squared
r_squared
#Ans) Model accuracy is around 49.5%

social_media_numeric <- social_media[, c('Instagram', 'LinkedIn', 'SnapChat', 'Twitter', 'Whatsapp/Wechat', 'youtube', 'OTT', 'Reddit', 'How many job interview calls received in this week.?', 'How much networking done with coffee chats?', 'How many learning done in terms of items created?')]

social_media_pca <- prcomp(social_media_numeric,scale=TRUE)
social_media_pca

summary(social_media_pca)
#Ans) The summary of the principal component analysis (PCA) shows the importance of each component:
#Standard deviation: This indicates the spread of the data along each principal component. Higher values indicate that the component explains more variability in the data.
#Proportion of Variance: This shows the proportion of the total variance in the data explained by each principal component. Higher values indicate that the component captures more information.
#Cumulative Proportion: This is the cumulative sum of the proportion of variance explained. It indicates how much of the total variance is explained by the first n components.


fviz_eig(social_media_pca, addlabels = TRUE)
#Ans) The graph shows that the sum of first 4 PCs is 69.7%. Hence first 4 PCs should be considered

PC1 <- social_media_pca$x[, 1]
PC2 <- social_media_pca$x[, 2]
PC3 <- social_media_pca$x[, 3]
PC4 <- social_media_pca$x[, 4]

pc_new <- data.frame(PC1, PC2, PC3, PC4)

pc_new$`Trouble falling asleep_numeric` <- social_media$`Trouble falling asleep_numeric`
pc_new

fit_new <- lm(`Trouble falling asleep_numeric` ~ PC1 + PC2 + PC3 + PC4, data=pc_new)
summary(fit_new)
#Ans) Here's a summary of the model:
#The intercept term has a coefficient of 0.3333 with a p-value of 0.00837, which is statistically significant.cNone of the principal components (PC1, PC2, PC3, PC4) have coefficients that are statistically significant (p-values are all greater than 0.05). The R-squared value is 0.1149, indicating that the model explains only a small portion of the variance in the "Trouble falling asleep_numeric" variable. Overall, based on this model, the principal components do not appear to be strong predictors of the "Trouble falling asleep_numeric" variable.

fa.parallel(social_media_numeric) 

fit.pc <- principal(social_media_numeric, nfactors=3, rotate="varimax")

round(fit.pc$values, 3)
fit.pc$loadings
#Ans) The loadings represent the correlation between each variable and the underlying factor. A higher absolute value of the loading indicates a stronger relationship between the variable and the factor. Variables with loadings close to 1 or -1 are strongly related to the factor. Variables with loadings close to 0 are weakly related to the factor and may not contribute much to it. Loadings that are similar in magnitude across multiple factors indicate that the variable is not clearly associated with any single factor. The SS loadings, Proportion Var, and Cumulative Var provide information about the amount of variance in the data explained by each component and cumulatively by all components.

loadings <- fit.pc$scores[, c("RC1", "RC2", "RC3")]
loadings_data <- as.data.frame(loadings)
loadings_data <- round(loadings_data, 3)

loadings_data$`Trouble falling asleep_numeric` <- social_media$`Trouble falling asleep_numeric`

fit_new_1 <- lm(`Trouble falling asleep_numeric`~RC1+RC2+RC3, data=loadings_data)
summary(fit_new_1)

#Ans) The regression results indicate that none of the regression coefficients for the factors (RC1, RC2, RC3) are statistically significant at conventional levels (p > 0.05). The overall model also does not seem to explain much of the variation in the Trouble falling asleep_numeric variable, as indicated by the low R-squared value and the non-significant F-statistic. This suggests that the factors derived may not be good predictors of the Trouble falling asleep_numeric variable.
```
```{r}
library(factoextra)
library(FactoMineR)
library(psych)
library(ggplot2)
library(cowplot)
library(caret)
library(e1071)
library(pROC)
library(readr)

social_media <- read_csv("/Users/tusharkishan/Desktop/Multivariate/Social\ Media/Social\ Media\ Logistic\ Regression/social_media_cleaned_new.csv")

str(social_media)

#Ans)A summary of responses from 21 individuals regarding their social media usage and various aspects of their week, such as mood, productivity, and sleep patterns. 
#Social Media Usage: The data includes columns for different social media platforms (e.g., Instagram, LinkedIn, Snapchat, Twitter, etc.) and the average time spent on each platform by the 21 individuals.
#Other Activities: The data also includes information about other activities, such as job interview calls received, networking done through coffee chats, and learning activities in terms of items created.
#Mood and Productivity: There is a column indicating whether individuals felt productive during the week, which could be correlated with their social media usage and other activities.
#Sleep Patterns: The data includes columns related to sleep, such as tiredness upon waking up and trouble falling asleep, both of which could be influenced by social media usage and daily activities.

social_media$`Trouble falling asleep_numeric` <- ifelse(social_media$`Trouble falling asleep` == "Yes", 1, 0)
str(social_media)
#Ans) A new column Trouble falling asleep_numeric is created where the values are 'num' data type

social_media$`Trouble falling asleep` <- ifelse(test = social_media$`Trouble falling asleep` == "Yes", yes = "Yes", no = "No")
 social_media$`Trouble falling asleep` <- as.factor(social_media$`Trouble falling asleep`)
str(social_media)
#) The column Trouble falling asleep is now a factor with 2 levels

logistic_simple <- glm(`Trouble falling asleep` ~ ., data = social_media, family = "binomial")
summary(logistic_simple)

#Ans) There are many predictor variables with very small estimates and large standard errors, which could indicate collinearity.The pr value is 1 in all columns, suggesting a weak link between the predictor and outcome variables.

new_data <- data.frame(probability.of.Trouble_falling_asleep=logistic_simple$fitted.values,Trouble_falling_asleep =social_media$`Trouble falling asleep`)
new_data <- new_data[order(new_data$probability.of.Trouble_falling_asleep, decreasing=FALSE),]
new_data$rank <- 1:nrow(new_data)

ggplot(data=new_data, aes(x=rank, y=probability.of.Trouble_falling_asleep)) +
geom_point(aes(color=Trouble_falling_asleep), alpha=1, shape=4, stroke=2) +
xlab("Index") +
ylab("Predicted probability of Trouble_falling_asleep")

#Ans) A scatter plot of probability.of.Trouble_falling_asleep against rank is where each point is colored based on the Trouble_falling_asleep variable.We can determine that the logistic regression assumptions are satisfied if there is no overlap.

data_new <- predict(logistic_simple,newdata=social_media,type="response" )
data_new

#Ans) We predict the response variable  for data stored in the social media dataset. The predicted probabilities of each level of the response variable for each observation in the social media dataset is calculated.

data_2 <- as.factor(ifelse(test=as.numeric(data_new>0.5) == "Yes", yes="Yes", no="No"))
data_2 <- factor(data_2, levels = levels(social_media$`Trouble falling asleep`))

confusionMatrix(data_2, social_media$`Trouble falling asleep`)
#Ans) The confusion matrix and statistics for predicting "Trouble falling asleep" are as follows:
#Accuracy: 0.6667
#95% CI: (0.4303, 0.8541)
#No Information Rate: 0.6667
#Kappa: 0
#Sensitivity: 1.0000
#Specificity: 0.0000
#Pos Pred Value: 0.6667
#Prevalence: 0.6667
#Detection Rate: 0.6667
#Detection Prevalence: 1.0000
#Balanced Accuracy: 0.5000
#This suggests that the model has a sensitivity of 1.0000 (all actual positive cases are correctly identified), but a specificity of 0.0000 (no actual negative cases are correctly identified), resulting in an overall accuracy of 0.6667. The Kappa statistic is 0, indicating no agreement between the model and the actual outcomes beyond that expected by chance.
```
```{r}
library(MASS)
library(ggplot2)
library(memisc)
library(ROCR)
library(dplyr)
library(klaR)


social_media <- read.csv("/Users/tusharkishan/Desktop/Multivariate/Social\ Media/Social\ Media\ LDA/social_media_cleaned_new.csv")
str(social_media)

social_media_2 <- social_media[, c("Instagram", "LinkedIn", "SnapChat", "Twitter", "Whatsapp.Wechat", "youtube", "OTT", "Reddit", "Trouble.falling.asleep")]

#Ans)A summary of responses from 21 individuals regarding their social media usage and various aspects of their week, such as mood, productivity, and sleep patterns. 
#Social Media Usage: The data includes columns for different social media platforms (e.g., Instagram, LinkedIn, Snapchat, Twitter, etc.) and the average time spent on each platform by the 21 individuals.
#Other Activities: The data also includes information about other activities, such as job interview calls received, networking done through coffee chats, and learning activities in terms of items created.
#Mood and Productivity: There is a column indicating whether individuals felt productive during the week, which could be correlated with their social media usage and other activities.
#Sleep Patterns: The data includes columns related to sleep, such as tiredness upon waking up and trouble falling asleep, both of which could be influenced by social media usage and daily activities.


social_media_2[social_media_2 == "?"] <- NA
social_media_2$`Trouble.falling.asleep` <- ifelse(social_media_2$`Trouble.falling.asleep` == "Yes", yes = "Yes", no = "No")

social_media_2[is.na(social_media_2)] <- mean(social_media_2, na.rm = TRUE)

r <- lda(formula = `Trouble.falling.asleep` ~ ., data = social_media_2)
r

#Ans) Here's a brief explanation of the output:

#Prior Probabilities of Groups: These are the estimated probabilities of belonging to each group (No, Yes) based on the class variable (Trouble falling asleep).
#Group Means: These are the mean values of each predictor variable (characteristics of social media usage) for each group (No, Yes). These values indicate the average level of each variable for each group.
#Coefficients of Linear Discriminants (LD): These coefficients are used to calculate the linear combination of predictors that forms the LD functions. The LD functions are used to classify observations into groups.
#LD1: This is the first linear discriminant function. It's a linear combination of the predictor variables that maximally separates the groups (No, Yes) based on Trouble falling asleep.
#Overall, LDA is used to find a linear combination of variables that best separates two or more classes in my data. The output provides information on how each predictor variable contributes to this separation.

r2 <- lda(formula = `Trouble.falling.asleep` ~ ., data = social_media_2, CV=TRUE)
r2

#Ans) Here's a brief explanation of the output:

#Class: This shows the predicted class for each observation based on the LDA model.
#Posterior: This matrix shows the posterior probabilities of each observation belonging to each class. In my output, NaN values indicate cases where the model cannot provide a valid posterior probability due to the data distribution.
#Terms: This section shows the formula used for the LDA model (Trouble falling asleep ~ .), which means predicting Trouble falling asleep based on all other variables in the dataset.
#Coefficients of Linear Discriminants (LD): These coefficients are used to calculate the linear combination of predictors that form the LD functions. These functions are used to classify observations into groups.
#$xlevels: This section shows the levels of the categorical variables used in the LDA model. For example, Mood Productivity has levels No and Yes, and Tired waking up in morning has levels No and Yes.
#Overall, LDA is used to find a linear combination of variables that best separates two or more classes in my data. The output provides information on how each predictor variable contributes to this separation.

train <- sample(1:15, 10)
r3 <- lda(`Trouble.falling.asleep` ~ ., 
          social_media_2,
          prior = c(0.5,0.5),
          subset = train)
r3
#Ans) Here's a summary of my findings
#Prior probabilities of groups: The model assumes equal prior probabilities for both classes: "No" and "Yes" for "Trouble falling asleep," with each having a prior probability of 0.5.
#Group means: For each group (No/Yes), the model provides the mean values for the predictor variables. For example, the mean value of charactertl868 for the "No" group is 0.0, while for the "Yes" group, it is 0.5.
#Coefficients of linear discriminants (LD1): These coefficients are used to transform the predictor variables into a new space where the groups are most separable. Each coefficient corresponds to a predictor variable and indicates the importance of that variable in determining the group.


llda <- predict(object = r3, newdata = social_media_2[-train, ])
head(llda$class)

head(llda$posterior, 6)
#Ans) Here's a breakdown for the first few rows:

#Observation 1: Highly likely "No" (0.9999915) and very unlikely "Yes" (8.485730e-06).
#Observation 2: Likely "Yes" (0.9846556) and unlikely "No" (0.0153444).
#Observation 3: Highly likely "No" (0.9997795) and very unlikely "Yes" (0.0002205493).
#Observation 4: Likely "No" (0.9310796) but somewhat likely "Yes" (0.06892039).
#Observation 5: Likely "Yes" (0.6461887) but somewhat likely "No" (0.3538113).
#Observation 6: Likely "No" (0.7645492) but somewhat likely "Yes" (0.2354508).

head(llda$x, 3)
#Ans) The llda$x output shows the linear discriminants (LD) for each observation. In this case, there is only one discriminant (LD1). Each row corresponds to an observation, and the value in the LD1 column represents the position of that observation along the LD1 axis. For example, for the first three observations:

#Observation 1: LD1 value is -4.431692.
#Observation 2: LD1 value is 1.579386.
#Observation 3: LD1 value is -3.195238.

plot(r)

plot(r3)
#Ans) All the observations are in one line and there is no overlap. 

training_sample <- sample(c(TRUE, FALSE), nrow(social_media_2), replace = T, prob = c(0.6,0.4))
train <- social_media_2[training_sample, ]
test <- social_media_2[!training_sample, ]
social_media_2[is.na(social_media_2)] <- mean(social_media_2, na.rm = TRUE)
lda.social_media <- lda(`Trouble.falling.asleep`~ ., train)

plot(lda.social_media, col = as.integer(train$`Trouble.falling.asleep`))
#Ans) There. is no overlap

lda.train <- predict(lda.social_media)
train$lda <- lda.train$class
table(train$lda,train$`Trouble.falling.asleep`)
#Ans) Accuracy of the model is excellent
```
```{r}

#) Learning and Takeaways
# From the anaysis done we can draw the following conclusions:
#The class can be seperated in 2 groups: one with students who spend more time on social media applications and one with students who spend less time.
#Some students are outliers, because they spend more time on certain types of apps than others.
#Some students are outliers, because they spend way less time on these apps compared to others.
#We also discovered which applications are most commonly used. This insight can be used to help simplify our study and gain a better understanding.
#Also the Regression models gave a very limited performance. The variables showed little importance in predicting outcomes.
```